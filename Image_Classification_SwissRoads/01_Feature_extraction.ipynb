{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <span style=\"color:blue\">**Feature Extraction**</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Function to count number of images in directories**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def fileCount(folder):\n",
    "    \n",
    "    '''\n",
    "        Counts the number of files inside the subdirectories of the different sets.\n",
    "        Returns number of images for training, validation and test sets.\n",
    "    '''\n",
    "    # Counters for the total number of images for:\n",
    "    test_cnt = 0 # test set\n",
    "    train_cnt = 0 # train set\n",
    "    valid_cnt = 0 # validation set\n",
    "\n",
    "    # Get subdirs from parent folder\n",
    "    subdirs = [ f.path for f in os.scandir(folder) if f.is_dir() ]\n",
    "    \n",
    "    # For each subdir\n",
    "    for subdir in subdirs:\n",
    "        \n",
    "        # Get subfolfer\n",
    "        subfolder = [ f.path for f in os.scandir(subdir) if f.is_dir() ]\n",
    "        \n",
    "        # Loop over the subfolders\n",
    "        for folder in subfolder:  \n",
    "            contents = os.listdir(folder) # list contents of the subfolder\n",
    "\n",
    "            # Update counters\n",
    "            if subdir.endswith('train'): \n",
    "                train_cnt += len(contents)\n",
    "            elif subdir.endswith('valid'): \n",
    "                valid_cnt += len(contents)\n",
    "            elif subdir.endswith('test'): \n",
    "                test_cnt += len(contents)\n",
    "    \n",
    "    return train_cnt, valid_cnt, test_cnt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Function to get data for training, validation and test & high level features according to a specific model**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from numpy import savez_compressed\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_high_level_features(model_url, model_name, train_batch_size, valid_batch_size, test_batch_size):\n",
    "    \n",
    "    '''\n",
    "        Open model with high level features and create necessary initializers  \n",
    "    '''\n",
    "    img_graph = tf.Graph()\n",
    "\n",
    "    with img_graph.as_default():\n",
    "        # Download module\n",
    "        feature_extractor = hub.Module(model_url)\n",
    "\n",
    "        # Get expected height, width \n",
    "        img_height, img_width = hub.get_expected_image_size(feature_extractor) \n",
    "\n",
    "        # Create input placeholder\n",
    "        input_imgs = tf.placeholder(dtype=tf.float32, shape=[None, img_height, img_width, 3])\n",
    "\n",
    "        # A node with the features\n",
    "        imgs_features = feature_extractor(input_imgs)\n",
    "\n",
    "        # Collect initializers\n",
    "        init_op = tf.group([\n",
    "            tf.global_variables_initializer(), tf.tables_initializer()\n",
    "        ])\n",
    "\n",
    "    img_graph.finalize() # make the graph \"read-only\" \n",
    "    \n",
    "    '''\n",
    "        Collect images in different sets\n",
    "    '''\n",
    "    \n",
    "    img_generator = ImageDataGenerator(rescale=1/255)# Create image generator same for all sets\n",
    "\n",
    "    # Create sets\n",
    "    trainset = img_generator.flow_from_directory(\n",
    "        os.path.join('swissroads', 'train'), batch_size=train_batch_size, target_size=(img_height, img_width), shuffle=False)\n",
    "\n",
    "    validset = img_generator.flow_from_directory(\n",
    "        os.path.join('swissroads', 'valid'), batch_size=valid_batch_size, target_size=(img_height, img_width), shuffle=False)\n",
    "\n",
    "    testset = img_generator.flow_from_directory(\n",
    "        os.path.join('swissroads', 'test'), batch_size=test_batch_size, target_size=(img_height, img_width), shuffle=False)\n",
    "    \n",
    "    # Collect all data from sets\n",
    "    X_tr, y_tr = trainset.next()\n",
    "    X_val, y_val = validset.next()\n",
    "    X_te, y_te = testset.next()\n",
    "    \n",
    "    # Collect the labels\n",
    "    tr_labels = list(trainset.class_indices)\n",
    "    tr_labels = np.array(tr_labels)\n",
    "    \n",
    "    val_labels = list(validset.class_indices)\n",
    "    val_labels = np.array(val_labels)\n",
    "    \n",
    "    te_labels = list(testset.class_indices)\n",
    "    te_labels = np.array(te_labels)\n",
    "    \n",
    "    # Collect filenames\n",
    "    X_tr_filenames = trainset.filenames\n",
    "    X_tr_filenames = [fname.split('/')[1] for fname in X_tr_filenames]\n",
    "    \n",
    "    X_val_filenames = validset.filenames\n",
    "    X_val_filenames = [fname.split('/')[1] for fname in X_val_filenames]\n",
    "    \n",
    "    X_te_filenames = testset.filenames\n",
    "    X_te_filenames = [fname.split('/')[1] for fname in X_te_filenames]\n",
    "    \n",
    "    '''\n",
    "        Extract high level features per set\n",
    "    '''    \n",
    "    # Create a session\n",
    "    sess = tf.Session(graph=img_graph)\n",
    "\n",
    "    # Initialize it\n",
    "    sess.run(init_op)\n",
    "\n",
    "    # Extract features\n",
    "    tr_features = sess.run(imgs_features, feed_dict={input_imgs: X_tr})\n",
    "    val_features = sess.run(imgs_features, feed_dict={input_imgs: X_val})\n",
    "    te_features = sess.run(imgs_features, feed_dict={input_imgs: X_te})    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "        Save sets and features to npz files\n",
    "    '''       \n",
    "    # Create dictionaries for each set\n",
    "    training_data = { 'data': X_tr, 'labels': y_tr, 'names':tr_labels, 'features': tr_features, 'filename': X_tr_filenames}\n",
    "    validation_data = { 'data': X_val, 'labels': y_val, 'names':val_labels, 'features': val_features, 'filename': X_val_filenames}\n",
    "    test_data = {'data': X_te, 'labels': y_te, 'names':te_labels, 'features': te_features, 'filename': X_te_filenames}\n",
    "    \n",
    "    # Save dictionaries to disk in npz format\n",
    "    np.savez_compressed('trainfile_'+model_name+'.npz', **training_data)\n",
    "    np.savez_compressed('validfile_'+model_name+'.npz', **validation_data)\n",
    "    np.savez_compressed('testfile_'+model_name+'.npz', **test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Get total number of images per set**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size, valid_batch_size, test_batch_size = fileCount('swissroads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Get data for training, validation and test & high level features**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### **1. Mobilenet_v2 model**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 images belonging to 6 classes.\n",
      "Found 139 images belonging to 6 classes.\n",
      "Found 50 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "model_url = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2'\n",
    "get_high_level_features(model_url, 'mobile_v2', train_batch_size, valid_batch_size, test_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### **2. Inception_v3 model**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 images belonging to 6 classes.\n",
      "Found 139 images belonging to 6 classes.\n",
      "Found 50 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "model_url = 'https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1'\n",
    "get_high_level_features(model_url, 'inception_v3', train_batch_size, valid_batch_size, test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
